@startuml
scale 1
class ClassificationTensorRT{
    __功能__
    API顶层接口
    __

    __构造&析构__

    __属性__
    +typedef struct classifier_ctx classifier_ctx
    +int device_
    __方法__
    +void getDevices(int* num)
    +void setDevice()
    +std::shared_ptr<classifier_ctx> classifier_initialize()
    +std::vector<std::vector<Prediction>> classifier_classify()
    +std::vector<cv::Mat> classifier_segment()
    +bool classifier_judge(std::shared_ptr<classifier_ctx>ctx, std::vector<cv::Mat>& pairImg, float threshold)
}
note right of ClassificationTensorRT::classifier_initialize()
    std::shared_ptr<classifier_ctx> classifier_initialize(
        std::string& onnx_file, std::string& engine_file,
        std::string& label_file, bool attachSoftmax,
        int maxBatch, int kContextsPerDevice,
        int numGpus, int data_type)
    1、初始化InferenceEngine
        std::shared_ptr<InferenceEngine> engine(new InferenceEngine(onnx_model, engine_name, attachSoftmax, maxBatch, dt));
    2、根据kContextsPerDevice，在每个GPU上创建多个ExecContext，并放到classifier_ctx的pool中
end note
note right of ClassificationTensorRT::classifier_classify()
    std::vector<std::vector<Prediction>> classifier_classify(
                std::shared_ptr<classifier_ctx>ctx,
                std::vector<cv::Mat>& batchImg)
    执行分类的函数，每一批图调用一次
end note

note right of ClassificationTensorRT::classifier_segment()
    std::vector<cv::Mat> classifier_segment(
                std::shared_ptr<classifier_ctx> ctx,
                std::vector<cv::Mat>& batchImg,
                bool probFormat = false)
end note
ClassificationTensorRT::classifier_ctx --> classifier_ctx


class ScopedContext{
    ..类功能..
   
    template <typename Context>
    __
    __构造 & 析构__
    +explicit ScopedContext(ContextPool<Context>& pool)
    +~ScopedContext()

    __属性__
    -ContextPool<Context>& pool_
	-std::unique_ptr<Context> context_
    __方法__
    +Context* operator->() const

    ContextPool<ExecContext> pool;
}
ScopedContext::pool --> ContextPool

class classifier_ctx{
    ..类功能..
    结构体
    ContextPool，API的执行上下文池
    __
    ContextPool<ExecContext> pool;
}
classifier_ctx "1" --> "many" ExecContext:包含
classifier_ctx::ContextPool --> ContextPool

class ContextPool{
    template <typename Context>
    using ContextPool = Queue<std::unique_ptr<Context>>
}
ContextPool --> Queue


class Queue{
    ..功能..
    构造个队列类
    __

    __构造 & 析构__
    +Queue() = default;
	+Queue(Queue&& other)

    __属性__
    -mutable std::mutex mutex_
	-std::queue<T> queue_
	-std::condition_variable cond_

    __方法__
    +void Push(T value)
    +T Pop()
    +size_t Size()
}


class ExecContext{
    ..类功能..
    API的执行上下文
    __
    {static} bool IsCompatible(int device)
    __属性__
    -int device_
    -std::unique_ptr<GPUAllocator> allocator_;
    -std::unique_ptr<Classifier> classifier_;
    #friend ScopedContext<ExecContext>

    __构造 & 析构__
    +ExecContext()
    __方法__
    -void Activate()
    -void Deactivate()
    +Classifier* TensorRTClassifier()
}
note left of ExecContext::ExecContext()
    ExecContext(
        std::shared_ptr<InferenceEngine> engine,
        bool isOnnx,
        const string& mean_file,
        const string& label_file,
        int device,
        int batch_size = 16,
        const string& input_blob = "data",
        const string& output_blob = "score"): device_(device)
        1、设定GPU
        2、构造allocator_
        3、构造classifier_
end note
ExecContext::allocator_ --> GPUAllocator :关联
ExecContext::classifier_ --> Classifier :关联
ExecContext::ScopedContext --> ScopedContext

class Classifier{
    ..类功能..
    前向推断具体执行类 （Engine --> Runtime）

    __属性__
    -GPUAllocator * allocator_
    -std::shared_ptr<InferenceEngine> engine_
    -SampleUniquePtr<IExecutionContext> context_
    -bool isOnnx_
    -GpuMat mean_
    -std::vector<string> labels_
    -DimsCHW input_dim_
    -Size input_cv_size_
    -float* input_layer_
    -DimsCHW output_dim_
    -float* output_layer_
    -int batch_size_
    -std::string input_blob_
    -std::string output_blob_
    __构造方法__
    +Classifier()
    +~Classifier()
    __方法__
    +std::vector<std::vector<Prediction>> Classify(const std::vector<Mat>& batchImg, int N = 5);
    +std::vector<cv::Mat> Segment(const std::vector<Mat>& batchImg, bool probFormat = false);
    +bool Judge(const std::vector<Mat>& pairImg, float T);
    +std::vector<std::vector<Detection>> Detect(const std::vector<Mat>& batchImg);
    -void SetModel();
    -void SetMean(const string& mean_file);
    -void SetLabels(const string& label_file);
    -std::vector<std::vector<float>> Predict(const std::vector<Mat>& batchImg);
    -void WrapInputLayer(std::vector<GpuMat>* input_channels, int idx);
    -void Preprocess(const Mat& img,	std::vector<GpuMat>* input_channels);

}
note left of Classifier::allocator_
    为Classifier分配GPU显存，
    使用OpencvGPU中的方法
end note
Classifier::allocator_ --> GPUAllocator : 关联
note right of Classifier::engine_
    指向InferenceEngine的共享指针
end note
Classifier::engine_ --> InferenceEngine : 关联
note right of Classifier::context_
    独立指针，
    指向nvinfer的IExecutioncontext类
end note
note left of Classifier::isOnnx_
    是否是onnx文件
end note
note left of Classifier::mean_
    输入图片的均值
end note
note left of Classifier::labels_
    labels
end note
note left of Classifier::input_dim_
    模型输入维度shape
end note
note left of Classifier::input_cv_size_
    图片输入维度shape
end note
note left of Classifier::input_layer_
    网络输入缓冲区，放到GPU上
end note
note left of Classifier::input_blob_
    网络输入名称
end note
note right of Classifier::Classifier()
    Classifier(std::shared_ptr<InferenceEngine> engine,
    bool isOnnx, const string& mean_file,const string& label_file, 
    GPUAllocator* allocator,const int& batch_size = 16,
    const string& input_blob = "data", 
    const string& output_blob = "score")
    SetModel():获取engine，设置上下文；为input和output开辟显存
    SetMean(...):均值设置
    SetLabels(...):标签设置
end note
note left of Classifier::SetModel()
    获取engine，设置执行上下文context_
    为input和output开辟显存空间
end note
note right of Classifier::~Classifier()
    释放input_layer_和output_layer_
end note
note right of Classifier::WrapInputLayer
    为网络输入(一张图片)分配GPU显存
end note
note right of Classifier::Preprocess
    1、检查图片和网络通道是否匹配
    2、resize image
    3、int2float
    4、归一化:但是没看到除均值这一步
end note 
note right of Classifier::Classify
    Predict
        WrapInputLayer()
        Preprocess()
        context_->executeV2(buffers)
        return batchOutputs
    处理batchOutputs，获得<Prediction>格式
end note
note right of Classifier::Segment
    Predict
        WrapInputLayer()
        Preprocess()
        context_->executeV2(buffers)
        return batchOutputs
    处理batchOutputs，获得<Mat>格式
end note


class GPUAllocator{
    ..类功能..
    分配GPU显存，继承自GpuMat::Allocator
    ..
    {static} int align_up(unsigned int v, unsigned int alignment)
    __构造 & 析构__
    +GPUAllocator(size_t size)
    +~GPUAllocator()

    __属性__
	-void* base_ptr_
	-void* current_ptr_
	-size_t total_size_
	-size_t current_size_
    __方法__
    +void reset()
    +bool allocate(GpuMat* mat, int rows, int cols, size_t elemSize)
	+void free(GpuMat* mat)
	-cudaError_t grow(void** dev_ptr, size_t size)
}


class InferenceEngine{
    ..类功能..
    推理引擎类：NetWork->Builder->Engine
    
    __属性__
    - std::shared_ptr<ICudaEngine> pEngine 

    __构造方法__
    +InferenceEngine()

    __方法__
    +ICudaEngine* deSerializeEngine()
    +ICudaEngine* Get()
}
note left of InferenceEngine::pEngine
    指向Engine的方法
end note
note left of InferenceEngine::InferenceEngine()
    1、通过序列化构造类
    InferenceEngine()
    2、通过onnx文件构造类
    InferenceEngine::InferenceEngine(
        const string& onnxModel, const string& engineName,
        bool attachSoftmax, int maxBatch, nvinfer1::DataType dataType)
end note
note left of InferenceEngine::deSerializeEngine()
    反序列化已经生成的引擎文件
end note


@enduml